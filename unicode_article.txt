A Programmerâ€™s Introduction to Unicode March 3, 2017 Â· Coding Â· 22 Comments  ï¼µï½ï½‰ï½ƒï½ï½„ï½…! ğŸ…¤ğŸ…ğŸ…˜ğŸ…’ğŸ…ğŸ…“ğŸ…”â€½ ğŸ‡º\u200cğŸ‡³\u200cğŸ‡®\u200cğŸ‡¨\u200cğŸ‡´\u200cğŸ‡©\u200cğŸ‡ª! ğŸ˜„ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to â€œsupport Unicodeâ€ in our software (whatever that meansâ€”like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I donâ€™t blame programmers for still finding the whole thing mysterious, even 30 years after Unicodeâ€™s inception.  A few months ago, I got interested in Unicode and decided to spend some time learning more about it in detail. In this article, Iâ€™ll give an introduction to it from a programmerâ€™s point of view.  Iâ€™m going to focus on the character set and whatâ€™s involved in working with strings and files of Unicode text. However, in this article Iâ€™m not going to talk about fonts, text layout/shaping/rendering, or localization in detailâ€”those are separate issues, beyond my scope (and knowledge) here.  Diversity and Inherent Complexity The Unicode Codespace Codespace Allocation Scripts Usage Frequency Encodings UTF-8 UTF-16 Combining Marks Canonical Equivalence Normalization Forms Grapheme Clusters And Moreâ€¦ Diversity and Inherent Complexity As soon as you start to study Unicode, it becomes clear that it represents a large jump in complexity over character sets like ASCII that you may be more familiar with. Itâ€™s not just that Unicode contains a much larger number of characters, although thatâ€™s part of it. Unicode also has a great deal of internal structure, features, and special cases, making it much more than what one might expect a mere â€œcharacter setâ€ to be. Weâ€™ll see some of that later in this article.  When confronting all this complexity, especially as an engineer, itâ€™s hard not to find oneself asking, â€œWhy do we need all this? Is this really necessary? Couldnâ€™t it be simplified?â€  However, Unicode aims to faithfully represent the entire worldâ€™s writing systems. The Unicode Consortiumâ€™s stated goal is â€œenabling people around the world to use computers in any languageâ€. And as you might imagine, the diversity of written languages is immense! To date, Unicode supports 135 different scripts, covering some 1100 languages, and thereâ€™s still a long tail of over 100 unsupported scripts, both modern and historical, which people are still working to add.  Given this enormous diversity, itâ€™s inevitable that representing it is a complicated project. Unicode embraces that diversity, and accepts the complexity inherent in its mission to include all human writing systems. It doesnâ€™t make a lot of trade-offs in the name of simplification, and it makes exceptions to its own rules where necessary to further its mission.  Moreover, Unicode is committed not just to supporting texts in any single language, but also to letting multiple languages coexist within one textâ€”which introduces even more complexity.  Most programming languages have libraries available to handle the gory low-level details of text manipulation, but as a programmer, youâ€™ll still need to know about certain Unicode features in order to know when and how to apply them. It may take some time to wrap your head around it all, but donâ€™t be discouragedâ€”think about the billions of people for whom your software will be more accessible through supporting text in their language. Embrace the complexity!  The Unicode Codespace Letâ€™s start with some general orientation. The basic elements of Unicodeâ€”its â€œcharactersâ€, although that term isnâ€™t quite rightâ€”are called code points. Code points are identified by number, customarily written in hexadecimal with the prefix â€œU+â€, such as U+0041 â€œAâ€ latin capital letter a or U+03B8 â€œÎ¸â€ greek small letter theta. Each code point also has a short name, and quite a few other prop
